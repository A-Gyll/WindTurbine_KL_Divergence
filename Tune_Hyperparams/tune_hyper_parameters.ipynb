{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujx4ab/ondemand/WindTurbine_KL_Divergence/.venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/ujx4ab/ondemand/WindTurbine_KL_Divergence/Data/combined_data.csv\"\n",
    "target_property = \"gearbox_temp_bin\"\n",
    "\n",
    "filtered_df = pd.read_csv(data_path)\n",
    "filtered_df.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "X = filtered_df.drop(target_property, axis=1)\n",
    "y = filtered_df[target_property]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions for Optuna\n",
    "def instantiate_pipeline(trial: optuna.Trial, model) -> Pipeline:\n",
    "    # Numerical imputer\n",
    "    imputer = SimpleImputer(strategy=trial.suggest_categorical('impute_strategy', ['mean', 'median', 'most_frequent']))\n",
    "    \n",
    "    # Standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Preprocessing pipeline for all features\n",
    "    preprocessor = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('scaler', scaler)\n",
    "    ])\n",
    "    \n",
    "    # Combine preprocessor and model\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "def instantiate_random_forest(trial: optuna.Trial) -> RandomForestClassifier:\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
    "    return RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "\n",
    "def instantiate_logistic_regression(trial: optuna.Trial) -> LogisticRegression:\n",
    "    C = trial.suggest_float('C', 1e-4, 10, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs'])\n",
    "    return LogisticRegression(C=C, solver=solver, random_state=42)\n",
    "\n",
    "def instantiate_knn(trial: optuna.Trial) -> KNeighborsClassifier:\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 3, 20)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    return KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial, X, y, model_type) -> float:\n",
    "    if model_type == 'random_forest':\n",
    "        model = instantiate_random_forest(trial)\n",
    "    elif model_type == 'logistic_regression':\n",
    "        model = instantiate_logistic_regression(trial)\n",
    "    elif model_type == 'knn':\n",
    "        model = instantiate_knn(trial)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    pipeline = instantiate_pipeline(trial, model)\n",
    "    \n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scorer = make_scorer(accuracy_score)  # Use accuracy for multi-class classification\n",
    "    scores = cross_val_score(pipeline, X, y, scoring=scorer, cv=kf)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna optimization\n",
    "def optimize_hyperparameters(X, y, model_type, n_trials=50):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X, y, model_type), n_trials=n_trials)\n",
    "    print(f\"Best trial for {model_type}:\")\n",
    "    print(study.best_trial.params)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-14 01:30:11,366] A new study created in memory with name: no-name-0180a877-fd17-48fd-9c51-c418a4811b34\n",
      "[I 2024-12-14 01:35:38,013] Trial 0 finished with value: 0.7627612788059626 and parameters: {'n_estimators': 116, 'max_depth': 16, 'impute_strategy': 'median'}. Best is trial 0 with value: 0.7627612788059626.\n",
      "[I 2024-12-14 01:38:55,917] Trial 1 finished with value: 0.7380804397511133 and parameters: {'n_estimators': 79, 'max_depth': 14, 'impute_strategy': 'mean'}. Best is trial 0 with value: 0.7627612788059626.\n",
      "[I 2024-12-14 01:43:23,095] Trial 2 finished with value: 0.6945925017737421 and parameters: {'n_estimators': 209, 'max_depth': 6, 'impute_strategy': 'mean'}. Best is trial 0 with value: 0.7627612788059626.\n",
      "[I 2024-12-14 02:00:48,273] Trial 3 finished with value: 0.9287171049023801 and parameters: {'n_estimators': 262, 'max_depth': 45, 'impute_strategy': 'mean'}. Best is trial 3 with value: 0.9287171049023801.\n",
      "[I 2024-12-14 02:14:34,617] Trial 4 finished with value: 0.7786291212442442 and parameters: {'n_estimators': 281, 'max_depth': 17, 'impute_strategy': 'mean'}. Best is trial 3 with value: 0.9287171049023801.\n",
      "[I 2024-12-14 02:34:34,716] Trial 5 finished with value: 0.928740949410751 and parameters: {'n_estimators': 300, 'max_depth': 42, 'impute_strategy': 'most_frequent'}. Best is trial 5 with value: 0.928740949410751.\n",
      "[I 2024-12-14 02:41:10,764] Trial 6 finished with value: 0.7216260179821943 and parameters: {'n_estimators': 181, 'max_depth': 12, 'impute_strategy': 'median'}. Best is trial 5 with value: 0.928740949410751.\n",
      "[I 2024-12-14 02:51:09,427] Trial 7 finished with value: 0.9173749830994457 and parameters: {'n_estimators': 158, 'max_depth': 27, 'impute_strategy': 'mean'}. Best is trial 5 with value: 0.928740949410751.\n",
      "[I 2024-12-14 03:05:20,857] Trial 8 finished with value: 0.9175244098038391 and parameters: {'n_estimators': 224, 'max_depth': 27, 'impute_strategy': 'most_frequent'}. Best is trial 5 with value: 0.928740949410751.\n",
      "[I 2024-12-14 03:23:26,166] Trial 9 finished with value: 0.8952343992701313 and parameters: {'n_estimators': 298, 'max_depth': 24, 'impute_strategy': 'most_frequent'}. Best is trial 5 with value: 0.928740949410751.\n",
      "[I 2024-12-14 03:26:56,412] Trial 10 finished with value: 0.9276218394835603 and parameters: {'n_estimators': 53, 'max_depth': 43, 'impute_strategy': 'most_frequent'}. Best is trial 5 with value: 0.928740949410751.\n",
      "[I 2024-12-14 03:43:57,720] Trial 11 finished with value: 0.9286678259468266 and parameters: {'n_estimators': 257, 'max_depth': 47, 'impute_strategy': 'most_frequent'}. Best is trial 5 with value: 0.928740949410751.\n"
     ]
    }
   ],
   "source": [
    "# Run optimization for each model type\n",
    "study_rf = optimize_hyperparameters(X_train, y_train, 'random_forest', n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 22:36:44,753] A new study created in memory with name: no-name-5d56456b-6dc2-45cc-b644-e572e0322b59\n",
      "[I 2024-12-13 22:37:03,951] Trial 0 finished with value: 0.6770581970209993 and parameters: {'C': 0.00043264085490664963, 'solver': 'lbfgs', 'impute_strategy': 'median'}. Best is trial 0 with value: 0.6770581970209993.\n",
      "/home/ujx4ab/ondemand/WindTurbine_KL_Divergence/.venv/lib64/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ujx4ab/ondemand/WindTurbine_KL_Divergence/.venv/lib64/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ujx4ab/ondemand/WindTurbine_KL_Divergence/.venv/lib64/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ujx4ab/ondemand/WindTurbine_KL_Divergence/.venv/lib64/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ujx4ab/ondemand/WindTurbine_KL_Divergence/.venv/lib64/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-12-13 22:37:46,814] Trial 1 finished with value: 0.6784634460393916 and parameters: {'C': 1.0974322879000786, 'solver': 'lbfgs', 'impute_strategy': 'median'}. Best is trial 1 with value: 0.6784634460393916.\n",
      "[I 2024-12-13 22:38:28,472] Trial 2 finished with value: 0.6726532818287313 and parameters: {'C': 0.10877731379413978, 'solver': 'liblinear', 'impute_strategy': 'most_frequent'}. Best is trial 1 with value: 0.6784634460393916.\n",
      "[I 2024-12-13 22:39:05,015] Trial 3 finished with value: 0.6729267013209977 and parameters: {'C': 0.008784901001212935, 'solver': 'liblinear', 'impute_strategy': 'median'}. Best is trial 1 with value: 0.6784634460393916.\n",
      "[I 2024-12-13 22:39:24,624] Trial 4 finished with value: 0.6777878455497797 and parameters: {'C': 0.0006226225182221211, 'solver': 'lbfgs', 'impute_strategy': 'most_frequent'}. Best is trial 1 with value: 0.6784634460393916.\n",
      "[I 2024-12-13 22:39:52,600] Trial 5 finished with value: 0.6784586770947588 and parameters: {'C': 0.0036676302925044936, 'solver': 'lbfgs', 'impute_strategy': 'mean'}. Best is trial 1 with value: 0.6784634460393916.\n",
      "[I 2024-12-13 22:40:36,831] Trial 6 finished with value: 0.6724768308773268 and parameters: {'C': 0.14995490352355328, 'solver': 'liblinear', 'impute_strategy': 'median'}. Best is trial 1 with value: 0.6784634460393916.\n",
      "[I 2024-12-13 22:41:31,317] Trial 7 finished with value: 0.6718823024464686 and parameters: {'C': 9.024446401747538, 'solver': 'liblinear', 'impute_strategy': 'median'}. Best is trial 1 with value: 0.6784634460393916.\n",
      "[I 2024-12-13 22:42:06,490] Trial 8 finished with value: 0.6729441874513171 and parameters: {'C': 0.007368915814719232, 'solver': 'liblinear', 'impute_strategy': 'most_frequent'}. Best is trial 1 with value: 0.6784634460393916.\n",
      "[I 2024-12-13 22:42:38,268] Trial 9 finished with value: 0.6706105838777878 and parameters: {'C': 0.0014857879867675435, 'solver': 'liblinear', 'impute_strategy': 'most_frequent'}. Best is trial 1 with value: 0.6784634460393916.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for logistic_regression:\n",
      "{'C': 1.0974322879000786, 'solver': 'lbfgs', 'impute_strategy': 'median'}\n"
     ]
    }
   ],
   "source": [
    "study_lr = optimize_hyperparameters(X_train, y_train, 'logistic_regression', n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 23:04:38,547] A new study created in memory with name: no-name-b4da92f1-cf68-4a3b-9b0a-eacf4283e266\n",
      "[I 2024-12-13 23:05:15,881] Trial 0 finished with value: 0.7241785492870427 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'impute_strategy': 'median'}. Best is trial 0 with value: 0.7241785492870427.\n",
      "[I 2024-12-13 23:05:57,770] Trial 1 finished with value: 0.7136534884829987 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'impute_strategy': 'most_frequent'}. Best is trial 0 with value: 0.7241785492870427.\n",
      "[I 2024-12-13 23:06:28,182] Trial 2 finished with value: 0.9236428378399861 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'impute_strategy': 'mean'}. Best is trial 2 with value: 0.9236428378399861.\n",
      "[I 2024-12-13 23:06:59,068] Trial 3 finished with value: 0.9231452779499897 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'impute_strategy': 'median'}. Best is trial 2 with value: 0.9236428378399861.\n",
      "[I 2024-12-13 23:07:38,796] Trial 4 finished with value: 0.7172683485144737 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'impute_strategy': 'most_frequent'}. Best is trial 2 with value: 0.9236428378399861.\n",
      "[I 2024-12-13 23:08:06,811] Trial 5 finished with value: 0.9219117109383692 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'impute_strategy': 'most_frequent'}. Best is trial 2 with value: 0.9236428378399861.\n",
      "[I 2024-12-13 23:08:36,861] Trial 6 finished with value: 0.9231452779499897 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'impute_strategy': 'most_frequent'}. Best is trial 2 with value: 0.9236428378399861.\n",
      "[I 2024-12-13 23:09:06,456] Trial 7 finished with value: 0.922469677460378 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'impute_strategy': 'median'}. Best is trial 2 with value: 0.9236428378399861.\n",
      "[I 2024-12-13 23:09:34,030] Trial 8 finished with value: 0.9207401402069723 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'impute_strategy': 'median'}. Best is trial 2 with value: 0.9236428378399861.\n",
      "[I 2024-12-13 23:09:55,564] Trial 9 finished with value: 0.9127632854849221 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'impute_strategy': 'median'}. Best is trial 2 with value: 0.9236428378399861.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for knn:\n",
      "{'n_neighbors': 18, 'weights': 'distance', 'impute_strategy': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "study_knn = optimize_hyperparameters(X_train, y_train, 'knn', n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best models on the test set\n",
    "def evaluate_model(X_train, X_test, y_train, y_test, study, model_type):\n",
    "    best_params = study.best_params\n",
    "    if model_type == 'random_forest':\n",
    "        best_model = instantiate_random_forest(optuna.trial.FixedTrial(best_params))\n",
    "    elif model_type == 'logistic_regression':\n",
    "        best_model = instantiate_logistic_regression(optuna.trial.FixedTrial(best_params))\n",
    "    elif model_type == 'knn':\n",
    "        best_model = instantiate_knn(optuna.trial.FixedTrial(best_params))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    pipeline = instantiate_pipeline(optuna.trial.FixedTrial(best_params), best_model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test accuracy for {model_type}: {test_accuracy}\")\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_train, X_test, y_train, y_test, study_rf, 'random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_train, X_test, y_train, y_test, study_lr, 'logistic_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_train, X_test, y_train, y_test, study_knn, 'knn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
